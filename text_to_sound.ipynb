{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ujjan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\df\\io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n"
     ]
    }
   ],
   "source": [
    "from df.enhance import enhance, init_df, save_audio\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoizer(noisy,output):\n",
    "    noisy_audio = noisy\n",
    "    # Initialize the model and state\n",
    "    model, df_state, _ = init_df()\n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(noisy_audio, sr=df_state.sr()) # Test loading the file\n",
    "    print(f\"Audio loaded successfully with sample rate: {sr}\")\n",
    "\n",
    "    # Convert the NumPy array to a PyTorch Tensor\n",
    "    audio_tensor = torch.tensor(audio, dtype=torch.float32)\n",
    "    # Add batch dimension: [1, num_samples]\n",
    "    audio_tensor = audio_tensor.unsqueeze(0)\n",
    "    # Enhance the audio\n",
    "    enhanced = enhance(model, df_state, audio_tensor)\n",
    "    # Remove batch dimension from the output\n",
    "    enhanced = enhanced.squeeze(0)\n",
    "    # Convert the enhanced tensor to a NumPy array\n",
    "    enhanced_np = enhanced.numpy()\n",
    "    output_path = output\n",
    "    sf.write(output_path, enhanced_np, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on torch 2.6.0+cpu\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on host Sundram\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\ujjan\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\ujjan\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cpu\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "Audio loaded successfully with sample rate: 48000\n"
     ]
    }
   ],
   "source": [
    "noize = r\"C:\\Users\\ujjan\\OneDrive\\Desktop\\python_projects\\GGWave\\noisy_snr0.wav\"\n",
    "output_path = r\"C:\\Users\\ujjan\\OneDrive\\Desktop\\python_projects\\GGWave\\enhanced.wav\"\n",
    "denoizer(noize,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__test__', 'decode', 'disableLog', 'enableLog', 'encode', 'free', 'getDefaultParameters', 'init', 're', 'rxToggleProtocol', 'txToggleProtocol']\n"
     ]
    }
   ],
   "source": [
    "import ggwave\n",
    "print(dir(ggwave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-29 01:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\ujjan\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\ujjan\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cpu\u001b[0m\n",
      "\u001b[32m2025-03-29 01:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "Audio loaded successfully with sample rate: 48000\n"
     ]
    }
   ],
   "source": [
    "noise = r\"C:\\Users\\ujjan\\OneDrive\\Desktop\\python_projects\\GGWave\\output.wav\"\n",
    "output_path = r\"C:\\Users\\ujjan\\OneDrive\\Desktop\\python_projects\\GGWave\\enhanced.wav\"\n",
    "denoizer(noise,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔊 Playing encoded sound...\n",
      "🔊 Playing encoded sound...\n",
      "🔊 Playing encoded sound...\n"
     ]
    }
   ],
   "source": [
    " import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "# ✅ Convert Text to Frequencies\n",
    "def text_to_sound(text):\n",
    "    sample_rate = 44100\n",
    "    duration = 2  # seconds\n",
    "    frequency = 1000 + (ord(text[0]) % 100) * 10  # Map character to frequency\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    sound_wave = 0.5 * np.sin(2 * np.pi * frequency * t)\n",
    "\n",
    "    print(\"🔊 Playing encoded sound...\")\n",
    "    sd.play(sound_wave, samplerate=sample_rate)\n",
    "    sd.wait()\n",
    "\n",
    "text_to_sound(\"H\")  # Send a character over sound\n",
    "text_to_sound(\"e\")  # Send a character over sound\n",
    "text_to_sound(\"l\")  # Send a character over sound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔠 Text: hello\n",
      "🖥 Binary: 0110100001100101011011000110110001101111\n",
      "🔊 Playing FSK-modulated sound...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fsk_wave_to_binary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     42\u001b[0m     wave\u001b[38;5;241m=\u001b[39mtext_to_fsk_sound(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Converts \"Hi\" to FSK sound\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     decoded_text \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_fsk_sound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwave\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Decode the waveform back to text\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoded Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoded_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m, in \u001b[0;36mdecode_fsk_sound\u001b[1;34m(waveform)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_fsk_sound\u001b[39m(waveform):\n\u001b[1;32m---> 35\u001b[0m     binary_data \u001b[38;5;241m=\u001b[39m \u001b[43mfsk_wave_to_binary\u001b[49m(waveform)\n\u001b[0;32m     36\u001b[0m     text \u001b[38;5;241m=\u001b[39m binary_to_text(binary_data)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fsk_wave_to_binary' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "# ✅ Parameters for FSK\n",
    "SAMPLE_RATE = 44100  # Standard audio sampling rate\n",
    "DURATION = 0.02  # Duration of each bit in seconds\n",
    "FREQ_0 = 2000  # Frequency for bit 0\n",
    "FREQ_1 = 4000  # Frequency for bit 1\n",
    "\n",
    "# ✅ Convert text to binary\n",
    "def text_to_binary(text):\n",
    "    return ''.join(format(ord(char), '08b') for char in text)\n",
    "\n",
    "# ✅ Generate FSK-modulated waveform\n",
    "def generate_fsk_wave(binary_data):\n",
    "    t = np.linspace(0, DURATION, int(SAMPLE_RATE * DURATION), False)\n",
    "    waveform = np.concatenate([\n",
    "        0.5 * np.sin(2 * np.pi * (FREQ_1 if bit == '1' else FREQ_0) * t)\n",
    "        for bit in binary_data\n",
    "    ])\n",
    "    return waveform\n",
    "\n",
    "# ✅ Play the sound\n",
    "def text_to_fsk_sound(text):\n",
    "    binary_data = text_to_binary(text)  # Convert text to binary\n",
    "    print(f\"🔠 Text: {text}\")\n",
    "    print(f\"🖥 Binary: {binary_data}\")\n",
    "\n",
    "    waveform = generate_fsk_wave(binary_data)  # Generate sound wave\n",
    "    print(\"🔊 Playing FSK-modulated sound...\")\n",
    "    \n",
    "    sd.play(waveform, samplerate=SAMPLE_RATE)  # Play the sound\n",
    "    sd.wait()\n",
    "def decode_fsk_sound(waveform):\n",
    "    binary_data = fsk_wave_to_binary(waveform)\n",
    "    text = binary_to_text(binary_data)\n",
    "    return text\n",
    "\n",
    "\n",
    "# 🚀 Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    wave=text_to_fsk_sound(\"hello\")  # Converts \"Hi\" to FSK sound\n",
    "    decoded_text = decode_fsk_sound(wave)  # Decode the waveform back to text\n",
    "    print(f\"Decoded Text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔠 Text: hello\n",
      "🖥 Binary: 0110100001100101011011000110110001101111\n",
      "🔊 Playing FSK-modulated sound...\n",
      "Decoded Text: None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "# ✅ Parameters for FSK\n",
    "SAMPLE_RATE = 44100  # Standard audio sampling rate\n",
    "DURATION = 0.02  # Duration of each bit in seconds\n",
    "FREQ_0 = 2000  # Frequency for bit 0\n",
    "FREQ_1 = 4000  # Frequency for bit 1\n",
    "\n",
    "# ✅ Convert text to binary\n",
    "def text_to_binary(text):\n",
    "    return ''.join(format(ord(char), '08b') for char in text)\n",
    "\n",
    "# ✅ Generate FSK-modulated waveform\n",
    "def generate_fsk_wave(binary_data):\n",
    "    t = np.linspace(0, DURATION, int(SAMPLE_RATE * DURATION), False)\n",
    "    waveform = np.concatenate([\n",
    "        0.5 * np.sin(2 * np.pi * (FREQ_1 if bit == '1' else FREQ_0) * t)\n",
    "        for bit in binary_data\n",
    "    ])\n",
    "    return waveform\n",
    "\n",
    "# ✅ Play the sound and return the waveform\n",
    "def text_to_fsk_sound(text):\n",
    "    binary_data = text_to_binary(text)  # Convert text to binary\n",
    "    print(f\"🔠 Text: {text}\")\n",
    "    print(f\"🖥 Binary: {binary_data}\")\n",
    "\n",
    "    waveform = generate_fsk_wave(binary_data)  # Generate sound wave\n",
    "    print(\"🔊 Playing FSK-modulated sound...\")\n",
    "    \n",
    "    sd.play(waveform, samplerate=SAMPLE_RATE)  # Play the sound\n",
    "    sd.wait()\n",
    "    \n",
    "    return waveform  # Return the waveform\n",
    "\n",
    "# ✅ Decode FSK waveform back to text\n",
    "def fsk_wave_to_binary(waveform):\n",
    "    # Placeholder for decoding logic\n",
    "    # Implement the decoding logic here\n",
    "    pass\n",
    "\n",
    "def binary_to_text(binary_data):\n",
    "    # Placeholder for binary-to-text conversion logic\n",
    "    # Implement the conversion logic here\n",
    "    pass\n",
    "\n",
    "def decode_fsk_sound(waveform):\n",
    "    binary_data = fsk_wave_to_binary(waveform)\n",
    "    text = binary_to_text(binary_data)\n",
    "    return text\n",
    "\n",
    "# 🚀 Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    wave = text_to_fsk_sound(\"hello\")  # Converts \"hello\" to FSK sound and returns the waveform\n",
    "    # The following decoding logic will work once `fsk_wave_to_binary` and `binary_to_text` are implemented\n",
    "    decoded_text = decode_fsk_sound(wave)  # Decode the waveform back to text\n",
    "    print(f\"Decoded Text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_fsk_sound(text):\n",
    "    binary_data = text_to_binary(text)  # Convert text to binary\n",
    "    print(f\" Text: {text}\") \n",
    "    print(f\" Binary: {binary_data}\") \n",
    "\n",
    "    waveform = generate_fsk_wave(binary_data)  # Generate sound wave\n",
    "    print(\"FSK-modulated sound generated.\") \n",
    "    sd.play(waveform, samplerate=SAMPLE_RATE)  # Play the sound\n",
    "    sd.wait()  # Wait until sound is finished playing\n",
    "    return waveform  # Return the generated waveform instead of playing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Text: hello \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "def fsk_wave_to_binary(waveform):\n",
    "    samples_per_bit = int(SAMPLE_RATE * DURATION)  # Number of samples per bit\n",
    "    binary_data = \"\"\n",
    "\n",
    "    for i in range(0, len(waveform), samples_per_bit):\n",
    "        segment = waveform[i:i+samples_per_bit]  # Extract bit-sized segment\n",
    "\n",
    "        # Hilbert transform to extract envelope (frequency detection)\n",
    "        analytic_signal = hilbert(segment)\n",
    "        amplitude_envelope = np.abs(analytic_signal)\n",
    "        \n",
    "        # Determine dominant frequency using zero-crossing rate\n",
    "        zero_crossings = np.where(np.diff(np.sign(segment)))[0]\n",
    "        frequency = len(zero_crossings) / (2 * DURATION)  # Approximate frequency\n",
    "\n",
    "        # Assign bit based on closest frequency\n",
    "        if abs(frequency - FREQ_1) < abs(frequency - FREQ_0):\n",
    "            binary_data += \"1\"\n",
    "        else:\n",
    "            binary_data += \"0\"\n",
    "\n",
    "    return binary_data\n",
    "\n",
    "# Convert binary back to text\n",
    "def binary_to_text(binary_data):\n",
    "    chars = [binary_data[i:i+8] for i in range(0, len(binary_data), 8)]\n",
    "    return ''.join(chr(int(char, 2)) for char in chars if len(char) == 8)\n",
    "\n",
    "#  Main decoding function\n",
    "def decode_fsk_sound(waveform):\n",
    "    binary_data = fsk_wave_to_binary(waveform)\n",
    "    text = binary_to_text(binary_data)\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wave = text_to_fsk_sound(\"hello \")  # Converts \"Hi\" to FSK sound\n",
    "    decoded_text = decode_fsk_sound(wave)  # Decode the waveform back to text\n",
    "    print(f\"Decoded Text: {decoded_text}\")  # Print the decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔠 Text: hello\n",
      "🖥 Binary: 0110100001100101011011000110110001101111\n",
      "🔊 Playing FSK-modulated sound...\n",
      "Decoded Text: hello\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "# Parameters for FSK\n",
    "SAMPLE_RATE = 44100  # Standard audio sampling rate\n",
    "DURATION = 0.02  # Duration of each bit in seconds\n",
    "FREQ_0 = 2000  # Frequency for bit 0\n",
    "FREQ_1 = 4000  # Frequency for bit 1\n",
    "\n",
    "# Convert text to binary\n",
    "def text_to_binary(text):\n",
    "    return ''.join(format(ord(char), '08b') for char in text)\n",
    "\n",
    "# Generate FSK-modulated waveform\n",
    "def generate_fsk_wave(binary_data):\n",
    "    t = np.linspace(0, DURATION, int(SAMPLE_RATE * DURATION), False)\n",
    "    waveform = np.concatenate([\n",
    "        0.5 * np.sin(2 * np.pi * (FREQ_1 if bit == '1' else FREQ_0) * t)\n",
    "        for bit in binary_data\n",
    "    ])\n",
    "    return waveform\n",
    "\n",
    "# Play the sound and return the waveform\n",
    "def text_to_fsk_sound(text):\n",
    "    binary_data = text_to_binary(text)  # Convert text to binary\n",
    "    print(f\"🔠 Text: {text}\")\n",
    "    print(f\"🖥 Binary: {binary_data}\")\n",
    "\n",
    "    waveform = generate_fsk_wave(binary_data)  # Generate sound wave\n",
    "    print(\"🔊 Playing FSK-modulated sound...\")\n",
    "    \n",
    "    sd.play(waveform, samplerate=SAMPLE_RATE)  # Play the sound\n",
    "    sd.wait()\n",
    "    \n",
    "    return waveform  # Return the waveform\n",
    "\n",
    "# Decode FSK waveform back to binary\n",
    "def fsk_wave_to_binary(waveform):\n",
    "    samples_per_bit = int(SAMPLE_RATE * DURATION)  # Number of samples per bit\n",
    "    binary_data = \"\"\n",
    "\n",
    "    for i in range(0, len(waveform), samples_per_bit):\n",
    "        segment = waveform[i:i+samples_per_bit]  # Extract bit-sized segment\n",
    "\n",
    "        # Hilbert transform to extract envelope (frequency detection)\n",
    "        analytic_signal = hilbert(segment)\n",
    "        amplitude_envelope = np.abs(analytic_signal)\n",
    "        \n",
    "        # Determine dominant frequency using zero-crossing rate\n",
    "        zero_crossings = np.where(np.diff(np.sign(segment)))[0]\n",
    "        frequency = len(zero_crossings) / (2 * DURATION)  # Approximate frequency\n",
    "\n",
    "        # Assign bit based on closest frequency\n",
    "        if abs(frequency - FREQ_1) < abs(frequency - FREQ_0):\n",
    "            binary_data += \"1\"\n",
    "        else:\n",
    "            binary_data += \"0\"\n",
    "\n",
    "    return binary_data\n",
    "\n",
    "# Convert binary back to text\n",
    "def binary_to_text(binary_data):\n",
    "    chars = [binary_data[i:i+8] for i in range(0, len(binary_data), 8)]\n",
    "    return ''.join(chr(int(char, 2)) for char in chars if len(char) == 8)\n",
    "\n",
    "# Decode FSK waveform back to text\n",
    "def decode_fsk_sound(waveform):\n",
    "    binary_data = fsk_wave_to_binary(waveform)\n",
    "    text = binary_to_text(binary_data)\n",
    "    return text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    wave = text_to_fsk_sound(\"hello\")  # Converts \"hello\" to FSK sound and returns the waveform\n",
    "    decoded_text = decode_fsk_sound(wave)  # Decode the waveform back to text\n",
    "    print(f\"Decoded Text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Speak something...\n",
      "📝 Recognized Text: hello hello hello\n",
      "🔠 Text: hello hello hello\n",
      "🖥 Binary: 0110100001100101011011000110110001101111001000000110100001100101011011000110110001101111001000000110100001100101011011000110110001101111\n",
      "🔊 Playing FSK-modulated sound...\n",
      "✅ Decoded Text: hello hello hello\n"
     ]
    }
   ],
   "source": [
    "#Main Code\n",
    "\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "# Parameters for FSK\n",
    "SAMPLE_RATE = 44100  # Standard audio sampling rate\n",
    "DURATION = 0.02  # Duration of each bit in seconds\n",
    "FREQ_0 = 2000  # Frequency for bit 0\n",
    "FREQ_1 = 4000  # Frequency for bit 1\n",
    "\n",
    "# Convert text to binary\n",
    "def text_to_binary(text):\n",
    "    return ''.join(format(ord(char), '08b') for char in text)\n",
    "\n",
    "# Generate FSK-modulated waveform\n",
    "def generate_fsk_wave(binary_data):\n",
    "    t = np.linspace(0, DURATION, int(SAMPLE_RATE * DURATION), False)\n",
    "    waveform = np.concatenate([\n",
    "        0.5 * np.sin(2 * np.pi * (FREQ_1 if bit == '1' else FREQ_0) * t)\n",
    "        for bit in binary_data\n",
    "    ])\n",
    "    return waveform\n",
    "\n",
    "# Play the sound and return the waveform\n",
    "def text_to_fsk_sound(text):\n",
    "    binary_data = text_to_binary(text)  # Convert text to binary\n",
    "    print(f\"🔠 Text: {text}\")\n",
    "    print(f\"🖥 Binary: {binary_data}\")\n",
    "\n",
    "    waveform = generate_fsk_wave(binary_data)  # Generate sound wave\n",
    "    print(\"🔊 Playing FSK-modulated sound...\")\n",
    "    \n",
    "    sd.play(waveform, samplerate=SAMPLE_RATE)  # Play the sound\n",
    "    sd.wait()\n",
    "    \n",
    "    return waveform  \n",
    "\n",
    "# Decode FSK waveform back to binary\n",
    "def fsk_wave_to_binary(waveform):\n",
    "    samples_per_bit = int(SAMPLE_RATE * DURATION)  # Number of samples per bit\n",
    "    binary_data = \"\"\n",
    "\n",
    "    for i in range(0, len(waveform), samples_per_bit):\n",
    "        segment = waveform[i:i+samples_per_bit]  # Extract bit-sized segment\n",
    "\n",
    "        # Hilbert transform to extract envelope (frequency detection)\n",
    "        analytic_signal = hilbert(segment)\n",
    "        amplitude_envelope = np.abs(analytic_signal)\n",
    "        \n",
    "        # Determine dominant frequency using zero-crossing rate\n",
    "        zero_crossings = np.where(np.diff(np.sign(segment)))[0]\n",
    "        frequency = len(zero_crossings) / (2 * DURATION)  # Approximate frequency\n",
    "\n",
    "        # Assign bit based on closest frequency\n",
    "        if abs(frequency - FREQ_1) < abs(frequency - FREQ_0):\n",
    "            binary_data += \"1\"\n",
    "        else:\n",
    "            binary_data += \"0\"\n",
    "\n",
    "    return binary_data\n",
    "\n",
    "# Convert binary back to text\n",
    "def binary_to_text(binary_data):\n",
    "    chars = [binary_data[i:i+8] for i in range(0, len(binary_data), 8)]\n",
    "    return ''.join(chr(int(char, 2)) for char in chars if len(char) == 8)\n",
    "\n",
    "# Decode FSK waveform back to text\n",
    "def decode_fsk_sound(waveform):\n",
    "    binary_data = fsk_wave_to_binary(waveform)\n",
    "    text = binary_to_text(binary_data)\n",
    "    return text\n",
    "\n",
    "# Speech recognition and FSK integration\n",
    "def record_text():\n",
    "    r = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"🎤 Speak something...\")\n",
    "            r.adjust_for_ambient_noise(source, duration=0.2)\n",
    "            audio = r.listen(source)\n",
    "            recognized_text = r.recognize_google(audio)\n",
    "            print(f\"📝 Recognized Text: {recognized_text}\")\n",
    "            return recognized_text\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results; {e}\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech recognition could not understand the audio.\")\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Record text using speech recognition\n",
    "    text = record_text()\n",
    "    if text:\n",
    "        # Step 2: Convert text to FSK-modulated sound\n",
    "        waveform = text_to_fsk_sound(text)\n",
    "        \n",
    "        # Step 3: Decode the FSK-modulated sound back to text\n",
    "        decoded_text = decode_fsk_sound(waveform)\n",
    "        print(f\"✅ Decoded Text: {decoded_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
